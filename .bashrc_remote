# .bashrc

# Source global definitions
if [ -f /etc/bashrc ]; then
    . /etc/bashrc
fi


# User specific aliases and functions
#####################################
### Basic Environmental Variables ###
#####################################
export HISTTIMEFORMAT='%F %T '
export HISTSIZE=10000
export LD_LIBRARY_PATH=/usr/local/lib
export PATH="/usr/bin:/usr/local/bin:$JAVA_HOME/bin:$PATH"
export PS1='\[\e[0;32m\]\u\[\e[m\]@\[\e[0;31m\]\h\[\e[m\] \[\e[0;33m\]$PWD\[\e[m\]]$ '
export TMOUT=0
export PROMPT_COMMAND=""
export PATH=/opt/anaconda2/bin:$PATH

###################################
### Basic aliases and functions ###
###################################
alias ls='ls -aF --color=auto'
alias tls='tmux list-session'
alias tnew='tmux new-session -s'
alias tre='tmux attach-session -d -t'
alias vi=vim

####################################
# Hadoop Environmental Variables ###
####################################
export PYSPARK_PYTHON=/opt/anaconda2/bin/python

######################
### Hadoop Aliases ###
######################
alias hls="snakebite ls"
alias hrm="snakebite rm"
alias hrmr="snakebite rmdir"
alias hmv="snakebite mv"
alias hmkdir="snakebite mkdir"
alias hmkdip="snakebite mkdirp"
alias hget="snakebite get"
alias htt="snakebite text"
alias hdf="snakebite df"
alias hdu="snakebite du"
alias hchmod="snakebite chmod"
alias hchown="snakebite chown"

alias ylog="yarn logs -applicationId"

# Run PySpark on Jupyter
function ipyspark {
  PYSPARK_DRIVER_PYTHON="/opt/anaconda2/bin/ipython"\
  pyspark "$@"
}

##################################
### Go Environmental Variables ###
##################################
export PATH=$PATH:/usr/local/go/bin
export GOPATH=$HOME/dev
export GOROOT=/usr/local/go

export PYENV_ROOT=$HOME/.pyenv
export PATH=$PYENV_ROOT/bin:$PATH
eval "$(pyenv init -)"
